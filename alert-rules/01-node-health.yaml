apiVersion: operator.victoriametrics.com/v1beta1
kind: VMRule
metadata:
  name: k3s-node-health
  namespace: victoria-metrics
  labels:
    app: vmalert
spec:
  groups:
    - name: k3s-node-health
      interval: 30s
      rules:
        # 1
        - alert: NodeDown
          expr: up{job="node-exporter"} == 0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Node {{ $labels.instance }} is down"
            description: "Node exporter on {{ $labels.instance }} has been unreachable for 5 minutes"

        # 2
        - alert: NodeNotReady
          expr: kube_node_status_condition{condition="Ready",status="true"} == 0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Node {{ $labels.node }} is not ready"
            description: "Node {{ $labels.node }} has been in NotReady state for 5 minutes"

        # 3
        - alert: NodeMemoryPressure
          expr: kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Node {{ $labels.node }} has memory pressure"
            description: "Node {{ $labels.node }} is experiencing memory pressure"

        # 4
        - alert: NodeDiskPressure
          expr: kube_node_status_condition{condition="DiskPressure",status="true"} == 1
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Node {{ $labels.node }} has disk pressure"
            description: "Node {{ $labels.node }} is experiencing disk pressure"

        # 5
        - alert: NodePIDPressure
          expr: kube_node_status_condition{condition="PIDPressure",status="true"} == 1
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Node {{ $labels.node }} has PID pressure"
            description: "Node {{ $labels.node }} is running low on available PIDs"

        # 6
        - alert: NodeNetworkUnavailable
          expr: kube_node_status_condition{condition="NetworkUnavailable",status="true"} == 1
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Node {{ $labels.node }} network unavailable"
            description: "Node {{ $labels.node }} network is not configured correctly"

        # 7
        - alert: NodeHighCPUUsage
          expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 85
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "High CPU usage on {{ $labels.instance }}"
            description: "CPU usage is above 85% (current: {{ $value | printf \"%.1f\" }}%)"

        # 8
        - alert: NodeCriticalCPUUsage
          expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 95
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Critical CPU usage on {{ $labels.instance }}"
            description: "CPU usage is above 95% (current: {{ $value | printf \"%.1f\" }}%)"

        # 9
        - alert: NodeHighMemoryUsage
          expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "High memory usage on {{ $labels.instance }}"
            description: "Memory usage is above 85% (current: {{ $value | printf \"%.1f\" }}%)"

        # 10
        - alert: NodeCriticalMemoryUsage
          expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 95
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Critical memory usage on {{ $labels.instance }}"
            description: "Memory usage is above 95% (current: {{ $value | printf \"%.1f\" }}%)"

        # 11
        - alert: NodeHighDiskUsage
          expr: (1 - (node_filesystem_avail_bytes{fstype!~"tmpfs|overlay"} / node_filesystem_size_bytes{fstype!~"tmpfs|overlay"})) * 100 > 80
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "High disk usage on {{ $labels.instance }} ({{ $labels.mountpoint }})"
            description: "Disk usage is above 80% (current: {{ $value | printf \"%.1f\" }}%)"

        # 12
        - alert: NodeCriticalDiskUsage
          expr: (1 - (node_filesystem_avail_bytes{fstype!~"tmpfs|overlay"} / node_filesystem_size_bytes{fstype!~"tmpfs|overlay"})) * 100 > 90
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Critical disk usage on {{ $labels.instance }} ({{ $labels.mountpoint }})"
            description: "Disk usage is above 90% (current: {{ $value | printf \"%.1f\" }}%)"

        # 13
        - alert: NodeDiskWillFillIn24Hours
          expr: predict_linear(node_filesystem_avail_bytes{fstype!~"tmpfs|overlay"}[6h], 24*3600) < 0
          for: 30m
          labels:
            severity: warning
          annotations:
            summary: "Disk on {{ $labels.instance }} will fill within 24 hours"
            description: "Filesystem {{ $labels.mountpoint }} is predicted to run out of space within 24 hours"

        # 14
        - alert: NodeHighLoadAverage
          expr: node_load15 / count without(cpu, mode) (node_cpu_seconds_total{mode="idle"}) > 2
          for: 15m
          labels:
            severity: warning
          annotations:
            summary: "High load average on {{ $labels.instance }}"
            description: "15-minute load average is more than 2x the number of CPUs"

        # 15
        - alert: NodeClockSkew
          expr: abs(node_timex_offset_seconds) > 0.05
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "Clock skew detected on {{ $labels.instance }}"
            description: "Clock offset is {{ $value | printf \"%.3f\" }} seconds"
